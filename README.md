# Confluence-Chatbot

Q. Why host your own LLM vs use OPen AI models. <br>
Q. FasiAPI for exposing model endpoints.Why not Flask<br>
Q. What is the load on API, user requests per month?<br>
Q. What is the confluence API limit(50-100 tokens at once)?<br>
Q. How did you take care of diagrams, tables in the confluence page?<br>
Q. Will the confluence API be hit everytime a user asks a question or there is fixed refresh rate?<br>
Q. What all prompt engineering was done?<br>
Q. How does the response of the llm model look like. Will it give Diagram and page links?<br>
Q. Which LLM model you chose and why?<br>
Q. Which embedding technique was used?<br>
Q. Which vector database was used?<br>
Q. How did you evaluate the performance of the model.<br>
Q. MLOps findings for the model.<br>
